{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (2.1.8)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (2.0.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (0.2.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied: blis<0.3.0,>=0.2.2 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (0.2.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (7.0.8)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (0.9.6)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (0.1.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from spacy) (1.16.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.6.16)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from thinc<7.1.0,>=7.0.8->spacy) (4.32.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: NLTK in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (3.4.4)\n",
      "Requirement already satisfied: six in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from NLTK) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kevin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run in python console\n",
    "import nltk; nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyLDAvis in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.10.1)\n",
      "Requirement already satisfied: numpy>=1.9.2 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.16.4)\n",
      "Requirement already satisfied: numexpr in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.6.9)\n",
      "Requirement already satisfied: funcy in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.13)\n",
      "Requirement already satisfied: scipy>=0.18.0 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.2.1)\n",
      "Requirement already satisfied: wheel>=0.23.0 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.33.4)\n",
      "Requirement already satisfied: future in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.17.1)\n",
      "Requirement already satisfied: pandas>=0.17.0 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.8.4 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.13.2)\n",
      "Requirement already satisfied: pytest in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pandas>=0.17.0->pyLDAvis) (2019.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pandas>=0.17.0->pyLDAvis) (2.8.0)\n",
      "Requirement already satisfied: py>=1.5.0 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (1.8.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (19.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (19.1.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (7.0.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (1.3.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (0.12.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (0.17)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (0.1.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from python-dateutil>=2.5.0->pandas>=0.17.0->pyLDAvis) (1.12.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from packaging->pytest->pyLDAvis) (2.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\kevin\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.12->pytest->pyLDAvis) (0.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rec.autos' 'comp.sys.mac.hardware' 'rec.motorcycles' 'misc.forsale'\n",
      " 'comp.os.ms-windows.misc' 'alt.atheism' 'comp.graphics'\n",
      " 'rec.sport.baseball' 'rec.sport.hockey' 'sci.electronics' 'sci.space'\n",
      " 'talk.politics.misc' 'sci.med' 'talk.politics.mideast'\n",
      " 'soc.religion.christian' 'comp.windows.x' 'comp.sys.ibm.pc.hardware'\n",
      " 'talk.politics.guns' 'talk.religion.misc' 'sci.crypt']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>From: irwin@cmptrc.lonestar.org (Irwin Arnstei...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>From: tchen@magnus.acs.ohio-state.edu (Tsung-K...</td>\n",
       "      <td>6</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>From: dabl2@nlm.nih.gov (Don A.B. Lindbergh)\\n...</td>\n",
       "      <td>2</td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>From: a207706@moe.dseg.ti.com (Robert Loper)\\n...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>From: kimman@magnus.acs.ohio-state.edu (Kim Ri...</td>\n",
       "      <td>6</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>From: kwilson@casbah.acns.nwu.edu (Kirtley Wil...</td>\n",
       "      <td>2</td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>Subject: Re: Don't more innocents die without ...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>From: livesey@solntze.wpd.sgi.com (Jon Livesey...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005</th>\n",
       "      <td>From: dls@aeg.dsto.gov.au (David Silver)\\nSubj...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10006</th>\n",
       "      <td>Subject: Re: Mike Francesa's 1993 Predictions\\...</td>\n",
       "      <td>9</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10007</th>\n",
       "      <td>From: jet@netcom.Netcom.COM (J. Eric Townsend)...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10008</th>\n",
       "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10009</th>\n",
       "      <td>From: sehari@iastate.edu (Babak Sehari)\\nSubje...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>From: danmg@grok85.ColumbiaSC.NCR.COM (Daniel ...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>From: henry@zoo.toronto.edu (Henry Spencer)\\nS...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>From: tzs@stein2.u.washington.edu (Tim Smith)\\...</td>\n",
       "      <td>18</td>\n",
       "      <td>talk.politics.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012</th>\n",
       "      <td>From: U56149@uicvm.uic.edu\\nSubject: LCIII &amp; M...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>From: nsmca@aurora.alaska.edu\\nSubject: Lunar ...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10014</th>\n",
       "      <td>From: acooper@mac.cc.macalstr.edu\\nSubject: Re...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10015</th>\n",
       "      <td>From: billc@col.hp.com (Bill Claussen)\\nSubjec...</td>\n",
       "      <td>13</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016</th>\n",
       "      <td>From: vestman@cs.umu.se (Peter Vestman)\\nSubje...</td>\n",
       "      <td>2</td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10017</th>\n",
       "      <td>From: nstramer@supergas.dazixco.ingr.com (Naft...</td>\n",
       "      <td>17</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10018</th>\n",
       "      <td>From: kohli@ecs.umass.edu\\nSubject: Mazda GLC ...</td>\n",
       "      <td>6</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10019</th>\n",
       "      <td>From: mussack@austin.ibm.com (Christopher Muss...</td>\n",
       "      <td>15</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>From: PA146008@utkvm1.utk.edu (David Veal)\\nSu...</td>\n",
       "      <td>18</td>\n",
       "      <td>talk.politics.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10020</th>\n",
       "      <td>From: noye@midway.uchicago.edu (vera shanti no...</td>\n",
       "      <td>15</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10021</th>\n",
       "      <td>From:  (Sean Garrison)\\nSubject: Re: WFAN\\nNnt...</td>\n",
       "      <td>9</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10022</th>\n",
       "      <td>From: christy@cs.concordia.ca (Christy)\\nSubje...</td>\n",
       "      <td>5</td>\n",
       "      <td>comp.windows.x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10023</th>\n",
       "      <td>From: mossman@cea.Berkeley.EDU (Amy Mossman)\\n...</td>\n",
       "      <td>13</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10024</th>\n",
       "      <td>From: yongje@hardy.u.washington.edu (Yong Je L...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10025</th>\n",
       "      <td>From: infante@acpub.duke.edu (Andrew  Infante)...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10026</th>\n",
       "      <td>From: healta@saturn.wwc.edu (Tammy R Healy)\\nS...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10027</th>\n",
       "      <td>From: doug@hparc0.aus.hp.com (Doug Parsons)\\nS...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10028</th>\n",
       "      <td>From: jsledd@ssdc.sas.upenn.edu (James Sledd)\\...</td>\n",
       "      <td>15</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10029</th>\n",
       "      <td>From: n4hy@tang.ccr-p.ida.org (Bob McGwier)\\nS...</td>\n",
       "      <td>18</td>\n",
       "      <td>talk.politics.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>From: u895027@franklin.cc.utas.edu.au (Mark Ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10030</th>\n",
       "      <td>From: baalke@kelvin.jpl.nasa.gov (Ron Baalke)\\...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10031</th>\n",
       "      <td>From: rauser@fraser.sfu.ca (Richard John Rause...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10032</th>\n",
       "      <td>From: steveg@cadkey.com (Steve Gallichio)\\nSub...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10033</th>\n",
       "      <td>From: keith@cco.caltech.edu (Keith Allan Schne...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10034</th>\n",
       "      <td>From: tedebear@leland.Stanford.EDU (Theodore C...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10035</th>\n",
       "      <td>From: chenmin@sage.cc.purdue.edu (zhang chenmi...</td>\n",
       "      <td>6</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10036</th>\n",
       "      <td>From: s851708@minyos.xx.rmit.OZ.AU (John Edmon...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10037</th>\n",
       "      <td>From: apoylis@inode.com\\nSubject:  FAQ on Cyri...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10038</th>\n",
       "      <td>From: oleg@sdd.comsat.com (Oleg Roytburd)\\nSub...</td>\n",
       "      <td>5</td>\n",
       "      <td>comp.windows.x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10039</th>\n",
       "      <td>From: rousseaua@immunex.com\\nSubject: Re: Lact...</td>\n",
       "      <td>13</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>From: cescript@mtu.edu (Charles Scripter)\\nSub...</td>\n",
       "      <td>16</td>\n",
       "      <td>talk.politics.guns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10040</th>\n",
       "      <td>From: dotsonm@dmapub.dma.org (Mark Dotson)\\nSu...</td>\n",
       "      <td>19</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  target  \\\n",
       "0      From: lerxst@wam.umd.edu (where's my thing)\\nS...       7   \n",
       "1      From: guykuo@carson.u.washington.edu (Guy Kuo)...       4   \n",
       "10     From: irwin@cmptrc.lonestar.org (Irwin Arnstei...       8   \n",
       "100    From: tchen@magnus.acs.ohio-state.edu (Tsung-K...       6   \n",
       "1000   From: dabl2@nlm.nih.gov (Don A.B. Lindbergh)\\n...       2   \n",
       "10000  From: a207706@moe.dseg.ti.com (Robert Loper)\\n...       7   \n",
       "10001  From: kimman@magnus.acs.ohio-state.edu (Kim Ri...       6   \n",
       "10002  From: kwilson@casbah.acns.nwu.edu (Kirtley Wil...       2   \n",
       "10003  Subject: Re: Don't more innocents die without ...       0   \n",
       "10004  From: livesey@solntze.wpd.sgi.com (Jon Livesey...       0   \n",
       "10005  From: dls@aeg.dsto.gov.au (David Silver)\\nSubj...       1   \n",
       "10006  Subject: Re: Mike Francesa's 1993 Predictions\\...       9   \n",
       "10007  From: jet@netcom.Netcom.COM (J. Eric Townsend)...       8   \n",
       "10008  From: gld@cunixb.cc.columbia.edu (Gary L Dare)...      10   \n",
       "10009  From: sehari@iastate.edu (Babak Sehari)\\nSubje...      12   \n",
       "1001   From: danmg@grok85.ColumbiaSC.NCR.COM (Daniel ...       7   \n",
       "10010  From: henry@zoo.toronto.edu (Henry Spencer)\\nS...      14   \n",
       "10011  From: tzs@stein2.u.washington.edu (Tim Smith)\\...      18   \n",
       "10012  From: U56149@uicvm.uic.edu\\nSubject: LCIII & M...       4   \n",
       "10013  From: nsmca@aurora.alaska.edu\\nSubject: Lunar ...      14   \n",
       "10014  From: acooper@mac.cc.macalstr.edu\\nSubject: Re...       0   \n",
       "10015  From: billc@col.hp.com (Bill Claussen)\\nSubjec...      13   \n",
       "10016  From: vestman@cs.umu.se (Peter Vestman)\\nSubje...       2   \n",
       "10017  From: nstramer@supergas.dazixco.ingr.com (Naft...      17   \n",
       "10018  From: kohli@ecs.umass.edu\\nSubject: Mazda GLC ...       6   \n",
       "10019  From: mussack@austin.ibm.com (Christopher Muss...      15   \n",
       "1002   From: PA146008@utkvm1.utk.edu (David Veal)\\nSu...      18   \n",
       "10020  From: noye@midway.uchicago.edu (vera shanti no...      15   \n",
       "10021  From:  (Sean Garrison)\\nSubject: Re: WFAN\\nNnt...       9   \n",
       "10022  From: christy@cs.concordia.ca (Christy)\\nSubje...       5   \n",
       "10023  From: mossman@cea.Berkeley.EDU (Amy Mossman)\\n...      13   \n",
       "10024  From: yongje@hardy.u.washington.edu (Yong Je L...       7   \n",
       "10025  From: infante@acpub.duke.edu (Andrew  Infante)...       8   \n",
       "10026  From: healta@saturn.wwc.edu (Tammy R Healy)\\nS...       0   \n",
       "10027  From: doug@hparc0.aus.hp.com (Doug Parsons)\\nS...       1   \n",
       "10028  From: jsledd@ssdc.sas.upenn.edu (James Sledd)\\...      15   \n",
       "10029  From: n4hy@tang.ccr-p.ida.org (Bob McGwier)\\nS...      18   \n",
       "1003   From: u895027@franklin.cc.utas.edu.au (Mark Ma...       1   \n",
       "10030  From: baalke@kelvin.jpl.nasa.gov (Ron Baalke)\\...      14   \n",
       "10031  From: rauser@fraser.sfu.ca (Richard John Rause...      10   \n",
       "10032  From: steveg@cadkey.com (Steve Gallichio)\\nSub...      10   \n",
       "10033  From: keith@cco.caltech.edu (Keith Allan Schne...       0   \n",
       "10034  From: tedebear@leland.Stanford.EDU (Theodore C...       7   \n",
       "10035  From: chenmin@sage.cc.purdue.edu (zhang chenmi...       6   \n",
       "10036  From: s851708@minyos.xx.rmit.OZ.AU (John Edmon...       8   \n",
       "10037  From: apoylis@inode.com\\nSubject:  FAQ on Cyri...       3   \n",
       "10038  From: oleg@sdd.comsat.com (Oleg Roytburd)\\nSub...       5   \n",
       "10039  From: rousseaua@immunex.com\\nSubject: Re: Lact...      13   \n",
       "1004   From: cescript@mtu.edu (Charles Scripter)\\nSub...      16   \n",
       "10040  From: dotsonm@dmapub.dma.org (Mark Dotson)\\nSu...      19   \n",
       "\n",
       "                   target_names  \n",
       "0                     rec.autos  \n",
       "1         comp.sys.mac.hardware  \n",
       "10              rec.motorcycles  \n",
       "100                misc.forsale  \n",
       "1000    comp.os.ms-windows.misc  \n",
       "10000                 rec.autos  \n",
       "10001              misc.forsale  \n",
       "10002   comp.os.ms-windows.misc  \n",
       "10003               alt.atheism  \n",
       "10004               alt.atheism  \n",
       "10005             comp.graphics  \n",
       "10006        rec.sport.baseball  \n",
       "10007           rec.motorcycles  \n",
       "10008          rec.sport.hockey  \n",
       "10009           sci.electronics  \n",
       "1001                  rec.autos  \n",
       "10010                 sci.space  \n",
       "10011        talk.politics.misc  \n",
       "10012     comp.sys.mac.hardware  \n",
       "10013                 sci.space  \n",
       "10014               alt.atheism  \n",
       "10015                   sci.med  \n",
       "10016   comp.os.ms-windows.misc  \n",
       "10017     talk.politics.mideast  \n",
       "10018              misc.forsale  \n",
       "10019    soc.religion.christian  \n",
       "1002         talk.politics.misc  \n",
       "10020    soc.religion.christian  \n",
       "10021        rec.sport.baseball  \n",
       "10022            comp.windows.x  \n",
       "10023                   sci.med  \n",
       "10024                 rec.autos  \n",
       "10025           rec.motorcycles  \n",
       "10026               alt.atheism  \n",
       "10027             comp.graphics  \n",
       "10028    soc.religion.christian  \n",
       "10029        talk.politics.misc  \n",
       "1003              comp.graphics  \n",
       "10030                 sci.space  \n",
       "10031          rec.sport.hockey  \n",
       "10032          rec.sport.hockey  \n",
       "10033               alt.atheism  \n",
       "10034                 rec.autos  \n",
       "10035              misc.forsale  \n",
       "10036           rec.motorcycles  \n",
       "10037  comp.sys.ibm.pc.hardware  \n",
       "10038            comp.windows.x  \n",
       "10039                   sci.med  \n",
       "1004         talk.politics.guns  \n",
       "10040        talk.religion.misc  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dataset\n",
    "df = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
    "print(df.target_names.unique())\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From: (wheres my thing) Subject: WHAT car is this!? Nntp-Posting-Host: '\n",
      " 'rac3.wam.umd.edu Organization: University of Maryland, College Park Lines: '\n",
      " '15 I was wondering if anyone out there could enlighten me on this car I saw '\n",
      " 'the other day. It was a 2-door sports car, looked to be from the late 60s/ '\n",
      " 'early 70s. It was called a Bricklin. The doors were really small. In '\n",
      " 'addition, the front bumper was separate from the rest of the body. This is '\n",
      " 'all I know. If anyone can tellme a model name, engine specs, years of '\n",
      " 'production, where this car is made, history, or whatever info you have on '\n",
      " 'this funky looking car, please e-mail. Thanks, - IL ---- brought to you by '\n",
      " 'your neighborhood Lerxst ---- ']\n"
     ]
    }
   ],
   "source": [
    "# Convert to list\n",
    "data = df.content.values.tolist()\n",
    "\n",
    "# Remove Emails\n",
    "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
    "\n",
    "# Remove new line characters\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "\n",
    "# Remove distracting single quotes\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "\n",
    "pprint(data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['from', 'wheres', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntp', 'posting', 'host', 'rac', 'wam', 'umd', 'edu', 'organization', 'university', 'of', 'maryland', 'college', 'park', 'lines', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front', 'bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst'], ['from', 'guy', 'kuo', 'subject', 'si', 'clock', 'poll', 'final', 'call', 'summary', 'final', 'call', 'for', 'si', 'clock', 'reports', 'keywords', 'si', 'acceleration', 'clock', 'upgrade', 'article', 'shelley', 'qvfo', 'innc', 'organization', 'university', 'of', 'washington', 'lines', 'nntp', 'posting', 'host', 'carson', 'washington', 'edu', 'fair', 'number', 'of', 'brave', 'souls', 'who', 'upgraded', 'their', 'si', 'clock', 'oscillator', 'have', 'shared', 'their', 'experiences', 'for', 'this', 'poll', 'please', 'send', 'brief', 'message', 'detailing', 'your', 'experiences', 'with', 'the', 'procedure', 'top', 'speed', 'attained', 'cpu', 'rated', 'speed', 'add', 'on', 'cards', 'and', 'adapters', 'heat', 'sinks', 'hour', 'of', 'usage', 'per', 'day', 'floppy', 'disk', 'functionality', 'with', 'and', 'floppies', 'are', 'especially', 'requested', 'will', 'be', 'summarizing', 'in', 'the', 'next', 'two', 'days', 'so', 'please', 'add', 'to', 'the', 'network', 'knowledge', 'base', 'if', 'you', 'have', 'done', 'the', 'clock', 'upgrade', 'and', 'havent', 'answered', 'this', 'poll', 'thanks', 'guy', 'kuo']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'wheres', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntp_posting_host', 'rac_wam_umd_edu', 'organization', 'university', 'of', 'maryland_college_park', 'lines', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front_bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst']\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['where', 's', 'thing', 'car', 'nntp_poste', 'host', 'umd', 'organization', 'university', 'maryland_college', 'park', 'line', 'wonder', 'anyone', 'could', 'enlighten', 'car', 'see', 'day', 'door', 'sport', 'car', 'look', 'late', 'early', 'call', 'bricklin', 'door', 'really', 'small', 'addition', 'front_bumper', 'separate', 'rest', 'body', 'know', 'anyone', 'tellme', 'model', 'name', 'engine', 'specs', 'year', 'production', 'car', 'make', 'history', 'info', 'funky', 'look', 'car', 'mail', 'thank', 'bring', 'neighborhood', 'lerxst']]\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, 1), (6, 5), (7, 1), (8, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 2), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'car'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('addition', 1),\n",
       "  ('anyone', 2),\n",
       "  ('body', 1),\n",
       "  ('bricklin', 1),\n",
       "  ('bring', 1),\n",
       "  ('call', 1),\n",
       "  ('car', 5),\n",
       "  ('could', 1),\n",
       "  ('day', 1),\n",
       "  ('door', 2),\n",
       "  ('early', 1),\n",
       "  ('engine', 1),\n",
       "  ('enlighten', 1),\n",
       "  ('front_bumper', 1),\n",
       "  ('funky', 1),\n",
       "  ('history', 1),\n",
       "  ('host', 1),\n",
       "  ('info', 1),\n",
       "  ('know', 1),\n",
       "  ('late', 1),\n",
       "  ('lerxst', 1),\n",
       "  ('line', 1),\n",
       "  ('look', 2),\n",
       "  ('mail', 1),\n",
       "  ('make', 1),\n",
       "  ('maryland_college', 1),\n",
       "  ('model', 1),\n",
       "  ('name', 1),\n",
       "  ('neighborhood', 1),\n",
       "  ('nntp_poste', 1),\n",
       "  ('organization', 1),\n",
       "  ('park', 1),\n",
       "  ('production', 1),\n",
       "  ('really', 1),\n",
       "  ('rest', 1),\n",
       "  ('s', 1),\n",
       "  ('see', 1),\n",
       "  ('separate', 1),\n",
       "  ('small', 1),\n",
       "  ('specs', 1),\n",
       "  ('sport', 1),\n",
       "  ('tellme', 1),\n",
       "  ('thank', 1),\n",
       "  ('thing', 1),\n",
       "  ('umd', 1),\n",
       "  ('university', 1),\n",
       "  ('where', 1),\n",
       "  ('wonder', 1),\n",
       "  ('year', 1)]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.048*\"mhz\" + 0.043*\"output\" + 0.043*\"input\" + 0.026*\"microsoft\" + '\n",
      "  '0.026*\"menu\" + 0.025*\"function\" + 0.025*\"lee\" + 0.020*\"documentation\" + '\n",
      "  '0.017*\"toolkit\" + 0.016*\"borland\"'),\n",
      " (1,\n",
      "  '0.021*\"god\" + 0.019*\"say\" + 0.017*\"people\" + 0.017*\"christian\" + '\n",
      "  '0.014*\"believe\" + 0.013*\"life\" + 0.013*\"man\" + 0.011*\"claim\" + '\n",
      "  '0.010*\"child\" + 0.010*\"word\"'),\n",
      " (2,\n",
      "  '0.062*\"illinoi\" + 0.041*\"urbana\" + 0.033*\"camera\" + 0.024*\"distance\" + '\n",
      "  '0.016*\"feb\" + 0.012*\"reed\" + 0.007*\"mapping\" + 0.002*\"pluto\" + '\n",
      "  '0.000*\"laptop\" + 0.000*\"fox\"'),\n",
      " (3,\n",
      "  '0.087*\"israel\" + 0.063*\"israeli\" + 0.043*\"arab\" + 0.033*\"international\" + '\n",
      "  '0.030*\"command\" + 0.028*\"gay\" + 0.025*\"homosexual\" + 0.022*\"professional\" + '\n",
      "  '0.020*\"count\" + 0.018*\"center\"'),\n",
      " (4,\n",
      "  '0.121*\"key\" + 0.044*\"encryption\" + 0.035*\"font\" + 0.031*\"clipper\" + '\n",
      "  '0.031*\"clipper_chip\" + 0.026*\"security\" + 0.024*\"algorithm\" + '\n",
      "  '0.022*\"secure\" + 0.021*\"bit\" + 0.020*\"proposal\"'),\n",
      " (5,\n",
      "  '0.199*\"space\" + 0.034*\"satellite\" + 0.031*\"science\" + 0.030*\"orbit\" + '\n",
      "  '0.029*\"flight\" + 0.028*\"earth\" + 0.025*\"spacecraft\" + 0.024*\"datum\" + '\n",
      "  '0.019*\"frank\" + 0.017*\"project\"'),\n",
      " (6,\n",
      "  '0.026*\"day\" + 0.021*\"car\" + 0.021*\"go\" + 0.017*\"news\" + 0.017*\"leave\" + '\n",
      "  '0.015*\"president\" + 0.011*\"kid\" + 0.011*\"home\" + 0.011*\"side\" + '\n",
      "  '0.011*\"turn\"'),\n",
      " (7,\n",
      "  '0.054*\"water\" + 0.030*\"escape\" + 0.029*\"massacre\" + 0.021*\"shut\" + '\n",
      "  '0.021*\"sea\" + 0.020*\"daughter\" + 0.019*\"cambridge\" + 0.019*\"sgi\" + '\n",
      "  '0.019*\"england\" + 0.016*\"exit\"'),\n",
      " (8,\n",
      "  '0.033*\"government\" + 0.027*\"gun\" + 0.026*\"state\" + 0.023*\"law\" + '\n",
      "  '0.019*\"country\" + 0.019*\"people\" + 0.018*\"right\" + 0.016*\"public\" + '\n",
      "  '0.016*\"american\" + 0.013*\"drug\"'),\n",
      " (9,\n",
      "  '0.039*\"year\" + 0.039*\"game\" + 0.037*\"team\" + 0.025*\"play\" + 0.024*\"win\" + '\n",
      "  '0.021*\"player\" + 0.017*\"hockey\" + 0.014*\"season\" + 0.014*\"guy\" + '\n",
      "  '0.013*\"hit\"'),\n",
      " (10,\n",
      "  '0.055*\"head\" + 0.042*\"fan\" + 0.040*\"league\" + 0.033*\"baseball\" + '\n",
      "  '0.028*\"tom\" + 0.027*\"doctor\" + 0.026*\"medical\" + 0.025*\"shot\" + '\n",
      "  '0.023*\"link\" + 0.022*\"bbs\"'),\n",
      " (11,\n",
      "  '0.046*\"morning\" + 0.045*\"jim\" + 0.036*\"prophecy\" + 0.034*\"patient\" + '\n",
      "  '0.034*\"usenet\" + 0.027*\"liar\" + 0.022*\"diet\" + 0.021*\"understanding\" + '\n",
      "  '0.019*\"island\" + 0.018*\"jet\"'),\n",
      " (12,\n",
      "  '0.857*\"ax\" + 0.060*\"max\" + 0.004*\"moon\" + 0.003*\"byte\" + 0.003*\"cd\" + '\n",
      "  '0.002*\"quadra\" + 0.002*\"counter\" + 0.002*\"centris\" + 0.002*\"db\" + '\n",
      "  '0.002*\"instruction\"'),\n",
      " (13,\n",
      "  '0.109*\"bike\" + 0.061*\"engine\" + 0.036*\"uk\" + 0.035*\"van\" + 0.027*\"duke\" + '\n",
      "  '0.021*\"hewlett_packard\" + 0.021*\"super\" + 0.019*\"keith\" + 0.017*\"bruce\" + '\n",
      "  '0.016*\"caltech\"'),\n",
      " (14,\n",
      "  '0.073*\"line\" + 0.065*\"organization\" + 0.031*\"university\" + 0.025*\"host\" + '\n",
      "  '0.022*\"article\" + 0.021*\"write\" + 0.016*\"reply\" + 0.015*\"nntp_poste\" + '\n",
      "  '0.014*\"thank\" + 0.014*\"new\"'),\n",
      " (15,\n",
      "  '0.058*\"file\" + 0.034*\"program\" + 0.033*\"information\" + 0.032*\"source\" + '\n",
      "  '0.029*\"page\" + 0.026*\"include\" + 0.021*\"copy\" + 0.021*\"available\" + '\n",
      "  '0.018*\"provide\" + 0.017*\"publish\"'),\n",
      " (16,\n",
      "  '0.039*\"not\" + 0.024*\"do\" + 0.021*\"would\" + 0.019*\"be\" + 0.016*\"know\" + '\n",
      "  '0.014*\"write\" + 0.014*\"get\" + 0.013*\"make\" + 0.012*\"think\" + 0.011*\"time\"'),\n",
      " (17,\n",
      "  '0.042*\"window\" + 0.037*\"card\" + 0.030*\"drive\" + 0.028*\"system\" + '\n",
      "  '0.025*\"use\" + 0.025*\"run\" + 0.022*\"software\" + 0.019*\"version\" + '\n",
      "  '0.017*\"problem\" + 0.016*\"bit\"'),\n",
      " (18,\n",
      "  '0.055*\"package\" + 0.046*\"apr\" + 0.041*\"air\" + 0.030*\"hall\" + 0.027*\"shop\" + '\n",
      "  '0.026*\"wave\" + 0.025*\"south\" + 0.024*\"coverage\" + 0.023*\"st\" + '\n",
      "  '0.022*\"complain\"'),\n",
      " (19,\n",
      "  '0.149*\"chip\" + 0.035*\"doug\" + 0.033*\"islam\" + 0.024*\"blindly\" + '\n",
      "  '0.024*\"default\" + 0.021*\"dan\" + 0.017*\"roman\" + 0.017*\"chain\" + '\n",
      "  '0.016*\"mary\" + 0.016*\"marc\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -14.691599440778381\n",
      "\n",
      "Coherence Score:  0.5215587403547935\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
